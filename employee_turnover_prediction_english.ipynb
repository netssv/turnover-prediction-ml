{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ec853e",
   "metadata": {},
   "source": [
    "# Employee Turnover Prediction Analysis - Kaggle Approach\n",
    "\n",
    "## Step 1 - Problem Definition and Target Variable\n",
    "\n",
    "**Problem to solve:**\n",
    "We want to predict whether an employee will leave the company (event = 1) or not (event = 0) based on their personal and work characteristics.\n",
    "\n",
    "**Target variable:** `event` (binary: 0 = no turnover, 1 = turnover)\n",
    "\n",
    "**Research question:** \n",
    "What employee characteristics (anxiety, extraversion, independence, self-control, age, tenure, etc.) are the best predictors to determine if an employee will leave the company?\n",
    "\n",
    "**Approach:** We will use machine learning techniques to create a predictive model that allows the company to identify employees at risk of leaving the organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Load and display data\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset with correct encoding\n",
    "df = pd.read_csv('turnover.csv', encoding='latin1')\n",
    "\n",
    "print(\"=== BASIC DATASET INFORMATION ===\")\n",
    "print(f\"Dataset dimensions: {df.shape}\")\n",
    "print(\"\\n=== FIRST 5 ROWS ===\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351acc5b",
   "metadata": {},
   "source": [
    "## Step 2 (continued) - Detailed dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed dataset information\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nTurnover distribution: {df['event'].value_counts().values}\")\n",
    "print(f\"Turnover percentage: {(df['event'].sum() / len(df)) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nNumeric columns: {len(df.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"Categorical columns: {len(df.select_dtypes(include=['object']).columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Exploratory Data Analysis (EDA)\n",
    "\n",
    "# Statistical summary and null values\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(df.describe())\n",
    "print(f\"\\nNull values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Histograms of numeric variables\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "n_cols = len(numeric_cols)\n",
    "n_rows = (n_cols + 2) // 3\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    plt.subplot(n_rows, 3, i + 1)\n",
    "    plt.hist(df[col], bins=20, alpha=0.7, edgecolor='black')\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aea456",
   "metadata": {},
   "source": [
    "## Step 3 (continued) - Correlations and categorical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix - Numeric Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation with target variable\n",
    "correlations_with_target = df.select_dtypes(include=[np.number]).corr()['event'].sort_values(ascending=False)\n",
    "print(\"CORRELATION WITH TURNOVER\")\n",
    "print(correlations_with_target.round(3))\n",
    "\n",
    "# Analysis of main categorical variables\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols[:3]:  # Only first 3 to keep it simple\n",
    "    print(f\"\\nTurnover by {col}:\")\n",
    "    print(df.groupby(col)['event'].mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b3763",
   "metadata": {},
   "source": [
    "## Step 4 - Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Data cleaning and preparation\n",
    "\n",
    "# Check null values\n",
    "print(f\"Null values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "df_processed = df.copy()\n",
    "categorical_cols = df_processed.select_dtypes(include=['object']).columns\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df_processed.drop('event', axis=1)\n",
    "y = df_processed['event']\n",
    "\n",
    "print(f\"Data prepared - X: {X.shape}, y: {y.shape}\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b09edf",
   "metadata": {},
   "source": [
    "## Step 5 - Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713f9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"DATA SPLITTING\")\n",
    "print(f\"Training: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing: {X_test.shape[0]} samples\")\n",
    "print(f\"Turnover in training: {(y_train.sum() / len(y_train)) * 100:.1f}%\")\n",
    "print(f\"Turnover in testing: {(y_test.sum() / len(y_test)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a14f1",
   "metadata": {},
   "source": [
    "## Step 6 - Base model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Base model (Random Forest)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"RANDOM FOREST - METRICS\")\n",
    "print(f\"Accuracy: {rf_accuracy:.3f}\")\n",
    "print(f\"Precision: {rf_precision:.3f}\")\n",
    "print(f\"Recall: {rf_recall:.3f}\")\n",
    "print(f\"F1-Score: {rf_f1:.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTOP 5 MOST IMPORTANT FEATURES\")\n",
    "print(feature_importance.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a357b7a",
   "metadata": {},
   "source": [
    "## Step 7 - Second model and comparison (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cdc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 - Second model (Logistic Regression) and comparison\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_precision = precision_score(y_test, y_pred_lr)\n",
    "lr_recall = recall_score(y_test, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "# Model comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Logistic Regression'],\n",
    "    'Accuracy': [rf_accuracy, lr_accuracy],\n",
    "    'Precision': [rf_precision, lr_precision],\n",
    "    'Recall': [rf_recall, lr_recall],\n",
    "    'F1-Score': [rf_f1, lr_f1]\n",
    "})\n",
    "\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(comparison_df.round(3).to_string(index=False))\n",
    "\n",
    "best_model_idx = comparison_df['F1-Score'].idxmax()\n",
    "best_model = comparison_df.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nBest model: {best_model}\")\n",
    "\n",
    "# Simplified visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, [rf_accuracy, rf_precision, rf_recall, rf_f1], width, \n",
    "        label='Random Forest', alpha=0.8)\n",
    "plt.bar(x + width/2, [lr_accuracy, lr_precision, lr_recall, lr_f1], width, \n",
    "        label='Logistic Regression', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Comparison')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfac781",
   "metadata": {},
   "source": [
    "## Analysis Conclusions\n",
    "\n",
    "### Summary of the 7 completed steps:\n",
    "\n",
    "1. **Problem definition**: Predict employee turnover (variable `event`)\n",
    "2. **Loading and exploration**: Dataset of 1,129 employees with 16 characteristics\n",
    "3. **EDA**: Statistical analysis, correlations and distributions\n",
    "4. **Preparation**: Encoding of 8 categorical variables\n",
    "5. **Splitting**: 80% training, 20% testing with stratification\n",
    "6. **Base model**: Random Forest with F1-Score of 0.723\n",
    "7. **Comparison**: Random Forest outperforms Logistic Regression\n",
    "\n",
    "### Main findings:\n",
    "- Most important variables: tenure (stag), age, industry\n",
    "- Random Forest: 70.8% accuracy, F1-Score: 0.723\n",
    "- Logistic Regression: 52.7% accuracy, F1-Score: 0.524\n",
    "- Balanced dataset (50.6% turnover) facilitates training\n",
    "\n",
    "### Recommendations:\n",
    "- Use Random Forest as production model\n",
    "- Monitor employees with high tenure\n",
    "- Implement alert system based on model probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa0fcc",
   "metadata": {},
   "source": [
    "## Practical Example - Prediction for New Employees\n",
    "\n",
    "Let's create examples of fictional employees and use our best model (Random Forest) to predict if they are at risk of turnover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 example employees with different profiles\n",
    "example_employees = pd.DataFrame({\n",
    "    'stag': [5.5, 45.0, 12.3, 78.2, 2.1],\n",
    "    'gender': [0, 1, 0, 1, 0],  # 0=female, 1=male\n",
    "    'age': [28, 45, 35, 52, 24],\n",
    "    'industry': [5, 2, 8, 1, 12],\n",
    "    'profession': [3, 7, 1, 9, 4],\n",
    "    'traffic': [2, 5, 1, 3, 4],\n",
    "    'coach': [1, 0, 2, 1, 0],\n",
    "    'head_gender': [0, 1, 1, 0, 1],\n",
    "    'greywage': [0, 1, 0, 1, 0],\n",
    "    'way': [1, 2, 0, 1, 2],\n",
    "    'extraversion': [6.2, 4.8, 7.1, 3.5, 8.2],\n",
    "    'independ': [5.8, 6.9, 4.3, 7.2, 5.1],\n",
    "    'selfcontrol': [6.1, 7.8, 5.2, 8.1, 4.9],\n",
    "    'anxiety': [4.5, 7.2, 5.8, 8.5, 3.2],\n",
    "    'novator': [6.8, 5.1, 7.3, 4.2, 8.1]\n",
    "})\n",
    "\n",
    "# Make predictions with Random Forest model\n",
    "predictions = rf_model.predict(example_employees)\n",
    "probabilities = rf_model.predict_proba(example_employees)\n",
    "\n",
    "# Create DataFrame with results\n",
    "results = pd.DataFrame({\n",
    "    'Employee': [f'Employee_{i+1}' for i in range(len(example_employees))],\n",
    "    'Age': example_employees['age'].values,\n",
    "    'Tenure': example_employees['stag'].values,\n",
    "    'Anxiety': example_employees['anxiety'].values,\n",
    "    'Prediction': ['Turnover' if p == 1 else 'Stays' for p in predictions],\n",
    "    'Turnover_Probability': [round(prob[1], 3) for prob in probabilities],\n",
    "    'Risk': ['High' if prob[1] > 0.7 else 'Medium' if prob[1] > 0.4 else 'Low' \n",
    "               for prob in probabilities]\n",
    "})\n",
    "\n",
    "print(\"Predictions for example employees:\")\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict turnover for an individual employee\n",
    "def predict_turnover(model, stag, age, anxiety, extraversion, independ, \n",
    "                     selfcontrol, novator, gender=0, industry=5, profession=3,\n",
    "                     traffic=2, coach=1, head_gender=0, greywage=0, way=1):\n",
    "    \"\"\"\n",
    "    Predicts turnover probability for an individual employee\n",
    "    \n",
    "    Main parameters (most important according to the model):\n",
    "    - stag: Tenure in months\n",
    "    - age: Age\n",
    "    - anxiety: Anxiety level (1-10)\n",
    "    - extraversion: Extraversion level (1-10)\n",
    "    - independ: Independence level (1-10)\n",
    "    - selfcontrol: Self-control level (1-10)\n",
    "    - novator: Innovation level (1-10)\n",
    "    \"\"\"\n",
    "    \n",
    "    employee = pd.DataFrame({\n",
    "        'stag': [stag], 'gender': [gender], 'age': [age], 'industry': [industry],\n",
    "        'profession': [profession], 'traffic': [traffic], 'coach': [coach],\n",
    "        'head_gender': [head_gender], 'greywage': [greywage], 'way': [way],\n",
    "        'extraversion': [extraversion], 'independ': [independ], \n",
    "        'selfcontrol': [selfcontrol], 'anxiety': [anxiety], 'novator': [novator]\n",
    "    })\n",
    "    \n",
    "    prediction = model.predict(employee)[0]\n",
    "    probability = model.predict_proba(employee)[0][1]\n",
    "    \n",
    "    result = \"Turnover\" if prediction == 1 else \"Stays\"\n",
    "    risk = \"High\" if probability > 0.7 else \"Medium\" if probability > 0.4 else \"Low\"\n",
    "    \n",
    "    return {\n",
    "        'prediction': result,\n",
    "        'turnover_probability': round(probability, 3),\n",
    "        'risk_level': risk\n",
    "    }\n",
    "\n",
    "# Individual usage example\n",
    "example_employee = predict_turnover(\n",
    "    model=rf_model,\n",
    "    stag=84.5,      # 2 years of tenure\n",
    "    age=32,         # 32 years old\n",
    "    anxiety=7.2,    # High anxiety\n",
    "    extraversion=5.5,\n",
    "    independ=6.0,\n",
    "    selfcontrol=4.8,\n",
    "    novator=6.5\n",
    ")\n",
    "\n",
    "print(\"Prediction for individual employee:\")\n",
    "for key, value in example_employee.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9380ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of predicting for 5 employees, predict only for John Smith\n",
    "john_smith = predict_turnover(\n",
    "    model=rf_model,\n",
    "    stag=1,      # John has 8 months in the company\n",
    "    age=36,         # John is 36 years old\n",
    "    anxiety=6.2,    # John has high anxiety\n",
    "    extraversion=8.5, # John has high extraversion\n",
    "    independ=7.0,   # John has high independence\n",
    "    selfcontrol=7.8, # John has high self-control\n",
    "    novator=9.5     # John has high innovation\n",
    ")\n",
    "print(\"\\nPrediction for John Smith:\")\n",
    "for key, value in john_smith.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Result: Only for John\n",
    "# prediction: Turnover\n",
    "# turnover_probability: 0.653\n",
    "# risk_level: Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4dc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis - Simple code\n",
    "\n",
    "# 1. Random Forest importance (already calculated)\n",
    "print(\"TOP 10 MOST IMPORTANT VARIABLES:\")\n",
    "print(\"-\" * 40)\n",
    "top_features = feature_importance.head(10)\n",
    "for i, row in top_features.iterrows():\n",
    "    print(f\"{row['Feature']:15s}: {row['Importance']:.3f}\")\n",
    "\n",
    "# 2. Simple importance visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10 = feature_importance.head(10)\n",
    "plt.barh(range(len(top_10)), top_10['Importance'])\n",
    "plt.yticks(range(len(top_10)), top_10['Feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Variables that most influence prediction')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Simple correlation with turnover\n",
    "print(\"\\nCORRELATION WITH TURNOVER:\")\n",
    "print(\"-\" * 30)\n",
    "correlations = df.select_dtypes(include=[np.number]).corr()['event'].abs().sort_values(ascending=False)\n",
    "for var, corr in correlations.head(8).items():\n",
    "    if var != 'event':\n",
    "        print(f\"{var:15s}: {corr:.3f}\")\n",
    "\n",
    "# 4. Quick analysis by groups (categorical variables)\n",
    "print(\"\\nTURNOVER DIFFERENCE BY GROUPS:\")\n",
    "print(\"-\" * 35)\n",
    "categorical_vars = ['gender', 'industry', 'profession', 'traffic']\n",
    "for var in categorical_vars:\n",
    "    if var in df.columns:\n",
    "        turnover_by_group = df.groupby(var)['event'].mean()\n",
    "        max_diff = turnover_by_group.max() - turnover_by_group.min()\n",
    "        print(f\"{var:15s}: maximum difference {max_diff:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
